from urllib.parse import urljoin

# ================= ğŸ”Œ æ’ä»¶é…ç½®å€ =================
# 1. ç›®æ¨™ç¶²å€ (ç›®éŒ„é )
CATALOG_URL = "https://czbooks.net/n/cpgjap8"

# 2. ç¶²ç«™ç‰¹æ€§æ¨™è¨˜
REVERSE_ORDER = False   # CZBooks ç›®éŒ„é€šå¸¸æ˜¯æ­£åºçš„ (ç¬¬1ç« åœ¨æœ€ä¸Šé¢)ï¼Œæ‰€ä»¥è¨­ False
NEED_LOGIN = False      # ä¸éœ€è¦ç™»å…¥

def parse_catalog(soup, base_url):
    """
    è§£æç›®éŒ„é ï¼Œå›å‚³ [(æ¨™é¡Œ, ç¶²å€), ...] åˆ—è¡¨
    """
    chapters = []

    # CZBooks çš„ç« ç¯€åˆ—è¡¨åœ¨ <ul class="nav chapter-list"> è£¡é¢
    chapter_list = soup.select("ul.nav.chapter-list li a")

    for link in chapter_list:
        title = link.get_text().strip()
        href = link.get('href')

        # éæ¿¾ç©ºé€£çµ
        if href and title:
            # è£œå…¨ç¶²å€ (é›–ç„¶ CZBooks é€šå¸¸æ˜¯çµ•å°è·¯å¾‘ï¼Œä½†åŠ ä¸Š urljoin æ›´ä¿éšª)
            full_url = urljoin(base_url, href)
            # ç°¡å–®å»é‡
            if not any(c[1] == full_url for c in chapters):
                chapters.append((title, full_url))

    return chapters

def parse_content(soup):
    """
    è§£æå…§æ–‡é ï¼Œå›å‚³ç´”æ–‡å­—
    """
    # CZBooks çš„æ­£æ–‡åœ¨ <div class="content"> è£¡é¢
    content_div = soup.select_one("div.content")

    if content_div:
        # ç§»é™¤å»£å‘Šæˆ–é›œè¨Š (CZBooks æœ‰æ™‚æœƒæœ‰ script æˆ– style)
        for trash in content_div(["script", "style", "div", "ins"]):
            trash.decompose()

        return content_div.get_text()

    return None
